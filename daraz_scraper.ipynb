{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "from numpy import random\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_category_names = []\n",
    "sub_category_urls = []\n",
    "sub_category_names = []\n",
    "final_category_urls = []\n",
    "final_category_names = []\n",
    "product_urls = []\n",
    "discounts = []\n",
    "brand_names = []\n",
    "product_skus = []\n",
    "currency_codes = []\n",
    "seller_names = []\n",
    "product_names = []\n",
    "product_prices = []\n",
    "chat_responses = []\n",
    "positive_sellers = []\n",
    "ship_on_times = []\n",
    "stars = []\n",
    "reviews = []\n",
    "delivery_times = []\n",
    "delivery_fees = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_category_url():\n",
    "    \n",
    "    source = requests.get(\"https://www.daraz.pk/\")\n",
    "    sleeptime = random.uniform(3, 8)\n",
    "    sleep(sleeptime)\n",
    "    \n",
    "    soup = BeautifulSoup(source.content, \"html.parser\")\n",
    "    urls = soup.find_all(\"ul\", {\"class\": \"lzd-site-menu-sub\"})\n",
    "\n",
    "    for url in urls:\n",
    "\n",
    "        c = url.find_all(\"li\", {\"class\": \"lzd-site-menu-sub-item\"})\n",
    "        d = url.find_all(\"li\", {\"class\": \"sub-item-remove-arrow\"})\n",
    "\n",
    "        for i in c:\n",
    "            sub_cat_url = i.find('a').get('href')\n",
    "            sub_category_urls.append(sub_cat_url)\n",
    "        for i in d:\n",
    "            sub_cat_url = i.find('a').get('href')\n",
    "            sub_category_urls.append(sub_cat_url)\n",
    "    \n",
    "    print(len(sub_category_urls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_final_category_url():\n",
    "    link = sub_category_urls[0]\n",
    "    url =f\"https:{link}\"\n",
    "\n",
    "    source = requests.get(url)\n",
    "    sleeptime = random.uniform(3, 8)\n",
    "    sleep(sleeptime)\n",
    "    soup = BeautifulSoup(source.content, \"html.parser\")\n",
    "    a = soup.find_all(\"script\")\n",
    "    a = a[7:131]\n",
    "    for i in a:\n",
    "        try:\n",
    "            i = str(i)\n",
    "            start = i.find(\">\")\n",
    "            dic = i[start+1:-9]\n",
    "            json_data = json.loads(dic)\n",
    "            for each in json_data:\n",
    "                try:\n",
    "                    url = each[\"childCategoryUrl\"]\n",
    "                    if url == '':\n",
    "                        pass\n",
    "                    else:\n",
    "                        final_category_urls.append(url)\n",
    "                except Exception as e:\n",
    "                    print(f\"Got exception in final_category_url: {str(e)}\")\n",
    "        except:\n",
    "            pass\n",
    "    print(len(final_category_urls))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_product_url():\n",
    "\n",
    "    for link in final_category_urls:\n",
    "        try:\n",
    "            url = f\"https:{link}\"\n",
    "            print(url)\n",
    "            source = requests.get(url, 'html.parser')\n",
    "            sleeptime = random.uniform(3, 8)\n",
    "            sleep(sleeptime)\n",
    "    \n",
    "            soup = BeautifulSoup(source.content, \"html.parser\")\n",
    "            script = soup.find_all(\"script\")\n",
    "            t =str(script[3])\n",
    "            start = t.find(\"totalResults\")\n",
    "            end = t.find(\"pageSize\")\n",
    "            item =int(t[start:end][15:-3])\n",
    "            total_page = math.ceil(item/40)\n",
    "            page = 1\n",
    "\n",
    "            for page in range(page, total_page+1):\n",
    "                page_url = f\"https:{link}?page={page}\"\n",
    "                print(page_url)\n",
    "                try:\n",
    "\n",
    "                    source = requests.get(page_url)\n",
    "                    sleeptime = random.uniform(1, 5)\n",
    "                    sleep(sleeptime)\n",
    "\n",
    "                    soup = BeautifulSoup(source.content, \"html.parser\")\n",
    "                    try:\n",
    "                        script = str(soup.find_all(\"script\")[-1])\n",
    "                        start = script.find(\">\")\n",
    "                        dic_of_data = script[start+1:-9]\n",
    "                        json_data = json.loads(dic_of_data)\n",
    "\n",
    "                        for each in json_data[\"itemListElement\"]:\n",
    "                            product_url = each[\"url\"]\n",
    "                            print(f\"Product Url: {product_url}\")\n",
    "                            product_urls.append(product_url)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Got exception in getting product_url: {str(e)}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Got exception in page_url: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Got exception in grand_cat_link: {str(e)}\")\n",
    "    print(len(product_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_data(product_url):\n",
    "    print(product_url)\n",
    "    try:\n",
    "        source = requests.get(product_url)\n",
    "        sleeptime = random.uniform(2, 5)\n",
    "        sleep(sleeptime)\n",
    "        soup = BeautifulSoup(source.content, \"html.parser\")\n",
    "        script = soup.find_all('script')\n",
    "        \n",
    "        \n",
    "        try:\n",
    "        \n",
    "            p = str(script[1])\n",
    "            p = p.replace(\"\\\\\", \"\")\n",
    "            start = p.find('''\"{''')\n",
    "            end = p.find('''\";''')\n",
    "            product = p[start+1:end]\n",
    "            data_item = json.loads(product)\n",
    "            \n",
    "            #rating&reviews\n",
    "            r = str(script[-11])\n",
    "            r_start = r.find('''{\"chatResponsiveRate\"''')\n",
    "            r_end = r.find(\"promotionTags\")\n",
    "            rating_data_r = r[r_start:r_end-2]\n",
    "            rating_r = json.loads(rating_data_r)\n",
    "            \n",
    "            # get_stars_reviews\n",
    "            s_start = r.find('''\"ratings\":''')\n",
    "            s_end = r.find(''',\"reportReasons\"''')\n",
    "            rating_data_s =r[s_start+10:s_end ] \n",
    "            rating_s = json.loads(rating_data_s)\n",
    "            \n",
    "            # get_diliverytime_fee\n",
    "            d_start = r.find('''\"duringTime\":''')\n",
    "            d_end = r.find(''',\"title\":\"Standard Delivery\"''')\n",
    "            dilivery_d = r[d_start:d_end-1].strip('''\"''').split(\",\")\n",
    "\n",
    "            \n",
    "            #category\n",
    "            try:\n",
    "                m_cat = data_item['pdt_category'][0]\n",
    "                main_category_names.append(m_cat)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in main_category: {str(e)}\")\n",
    "                main_category_names.append(\" \")\n",
    "            try:\n",
    "                s_cat = data_item['pdt_category'][1]\n",
    "                sub_category_names.append(s_cat)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in sub_category: {str(e)}\")\n",
    "                sub_category_names.append(\" \")\n",
    "            try:\n",
    "                f_cat = data_item['pdt_category'][2]\n",
    "                final_category_names.append(f_cat)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in final_category: {str(e)}\")\n",
    "                final_category_names.append(\" \")\n",
    "\n",
    "            #discount\n",
    "\n",
    "            try:\n",
    "                discount = data_item['pdt_discount']\n",
    "                discounts.append(discount)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in discount: {str(e)}\")\n",
    "                discounts.append(\" \")\n",
    "\n",
    "            #brand_name\n",
    "\n",
    "            try:\n",
    "                brand_name = data_item['brand_name']\n",
    "                brand_names.append(brand_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in brand_name: {str(e)}\")\n",
    "                brand_names.append(\" \")\n",
    "\n",
    "            #product_sku\n",
    "\n",
    "            try:\n",
    "                product_sku = data_item['pdt_sku']\n",
    "                product_skus.append(product_sku)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in product_sku: {str(e)}\")\n",
    "                product_skus.append(\" \")\n",
    "\n",
    "            #product_names\n",
    "\n",
    "            try:\n",
    "                product_name = data_item['pdt_name']\n",
    "                product_names.append(product_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in product_name: {str(e)}\")\n",
    "                product_names.append(\" \")\n",
    "\n",
    "\n",
    "            #product_price\n",
    "\n",
    "            try:\n",
    "                product_price = data_item['pdt_price']\n",
    "                product_prices.append(product_price)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in product_price: {str(e)}\")\n",
    "                product_prices.append(\" \")\n",
    "\n",
    "\n",
    "\n",
    "            #currency_code\n",
    "\n",
    "            try:\n",
    "                currency_code = data_item['core']['currencyCode']\n",
    "                currency_codes.append(currency_code)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in currency_code: {str(e)}\")\n",
    "                currency_codes.append(\" \")\n",
    "\n",
    "            #seller_name\n",
    "\n",
    "            try:\n",
    "                seller_name = data_item['seller_name']\n",
    "                seller_names.append(seller_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in seller_name: {str(e)}\")\n",
    "                seller_names.append(\" \")\n",
    "\n",
    "\n",
    "         \n",
    "            #rating&reviews\n",
    "            try:\n",
    "                chat_response = rating_r['chatResponsiveRate']['value']\n",
    "                chat_responses.append(chat_response)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in chat_response: {str(e)}\")\n",
    "                chat_responses.append(\" \")\n",
    "\n",
    "            try:\n",
    "                positive_seller = rating_r['positiveSellerRating']['value']\n",
    "                positive_sellers.append(positive_seller)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in positive_seller: {str(e)}\")\n",
    "                positive_sellers.append(\" \")\n",
    "\n",
    "            try:\n",
    "                ship_on_time = rating_r['shipOnTime']['value']\n",
    "                ship_on_times.append(ship_on_time)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in ship_on_time: {str(e)}\")\n",
    "                ship_on_times.append(\" \")\n",
    "               \n",
    "            # get_stars_reviews\n",
    "            try:\n",
    "                star = rating_s['average']\n",
    "                stars.append(star)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in star: {str(e)}\")\n",
    "                stars.append(\" \")\n",
    "\n",
    "            try:\n",
    "                review = rating_s['reviewCount']\n",
    "                reviews.append(review)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in review: {str(e)}\")\n",
    "                reviews.append(\" \")\n",
    "\n",
    "            # get_diliverytime_fee\n",
    "            try:\n",
    "                delivery_time = dilivery_d[0][13:-1].strip('''(s)''')\n",
    "                delivery_times.append(delivery_time)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in delivery time: {str(e)}\")\n",
    "                delivery_times.append(\" \")\n",
    "\n",
    "            try:    \n",
    "                delivery_fee = dilivery_d[2][11:]\n",
    "                delivery_fees.append(delivery_fee)\n",
    "            except Exception as e:\n",
    "                print(f\"Got exception in delivery fee: {str(e)}\")\n",
    "                delivery_fees.append(\" \")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Got exception in product_data: {str(e)}\")\n",
    "            product_urls.append(product_url)\n",
    "    except Exception as e:\n",
    "        print(f\"Got exception in product_url: {str(e)}\")\n",
    "        product_urls.append(product_url)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sub_category_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_final_category_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_product_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product_url in product_urls:\n",
    "    get_product_data(product_url)\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
